{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2a5bd5c",
   "metadata": {},
   "source": [
    "## Step 4-C: Modeling\n",
    "### Gradient Boosting Classifier\n",
    "\n",
    "I decided to try a Gradient Boost model to see if I could reduce the variance. \n",
    "\n",
    "Due to the slowness of grid searching over many parameters, I used the Count Vectorizer parameters that I had previously determined when modeling with Multinomial Naive Bayes. I only gridsearched parameters for the Gradient Booster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f45b57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16b17bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "983dbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quick clean-up task that leaked into modeling\n",
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c762d68",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df7ef465",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns = ['subreddit','created_utc'])\n",
    "y = df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5725e83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.284551\n",
       "2    0.258203\n",
       "1    0.232724\n",
       "3    0.224522\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Baseline\n",
    "#Anxiety = 0, ADHD = 1, Depression = 2, Autism = 3\n",
    "y.value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96fe343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c150535",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words = 'english', max_df = .9, max_features = 4000)\n",
    "Xcvec_train = cvec.fit_transform(X_train['selftext'])\n",
    "Xcvec_test = cvec.transform(X_test['selftext'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2589fbe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12069x4000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 585859 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xcvec_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bf7f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_train_df = pd.DataFrame(Xcvec_train.todense(), columns=cvec.get_feature_names())\n",
    "Xcv_test_df = pd.DataFrame(Xcvec_test.todense(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1851184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcv_train_df.reset_index(drop=True, inplace=True)\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "Xcv_test_df.reset_index(drop=True, inplace = True)\n",
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36ba76ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all = pd.concat([Xcv_train_df, X_train], axis=1)\n",
    "X_test_all = pd.concat([Xcv_test_df, X_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "040942a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_all.drop(columns = 'selftext', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "360aa398",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_all.drop(columns = 'selftext', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b6e432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12069, 4006), (12069,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_all.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397f49b2",
   "metadata": {},
   "source": [
    "### Modeling with GBoost\n",
    "\n",
    "I actually did a few different grid searches where I included the \"best\" parameters and at least one other pair. The best parameters of the grid search below were consistent across several different searches.\n",
    "\n",
    "The accuracy of this model was about the same as the others, but the variance gap closed a tiny bit. \n",
    "\n",
    "As with Random Forest, this model is able to take into consideration the sentiment analysis scores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69ae7198",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db04430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': [75,50],\n",
    "          'max_depth': [2, 3],\n",
    "         'learning_rate' : [1.2, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fb6520a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_gs = GridSearchCV(gb, params, cv = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03ce6395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=GradientBoostingClassifier(),\n",
       "             param_grid={'learning_rate': [1.2, 1], 'max_depth': [2, 3],\n",
       "                         'n_estimators': [75, 50]})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.fit(X_train_all, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "799d7c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8447261579252631, 0.7638578175490928)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.score(X_train_all, y_train), gb_gs.score(X_test_all, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6a5d71f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1, 'max_depth': 2, 'n_estimators': 75}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c8b4a5",
   "metadata": {},
   "source": [
    "# Step 5: Evaluation\n",
    "\n",
    "Overall, all three models had very similar performance. All are overfit to the training data. I had originally collected a smaller data set and hoped that more data might help address the overfit issue. However, when I collected more data, the accuracy of the models actual decreased as well as the variance. \n",
    "\n",
    "| Model                     | Test Accuracy | Train Accuracy | Best Parameters                                                                                            |\n",
    "|---------------------------|---------------|----------------|------------------------------------------------------------------------------------------------------------|\n",
    "| Multinomial Naive Bayes   | 85%           | 75%            | max_df: 0.9<br>max_features: 5000<br>min_df: 3<br>ngram_range: (1, 2)                                      |\n",
    "| Random Forest Classifier  | 83%           | 76%            | max_depth: 19<br>max_features: 'auto'<br>min_samples_leaf: 2<br>min_samples_split: 4<br>n_estimators: 1000 |\n",
    "| Gradient Boost Classifier | 84%           | 77%            | learning rate: 1<br>max_depth: 2<br>n_estimators: 50                                                       |\n",
    "\n",
    "There are a number of steps that I could take to further optimize these models:\n",
    "- GridSearch over both CountVectorizer and model parameters within the same pipeline\n",
    "- Lemmatize the data\n",
    "- Create a more thorough custom stop-words list\n",
    "- Try TFIDF instead of CVec\n",
    "\n",
    "# Step 6: Conclusions & Recommendations\n",
    "\n",
    "I would recommend the GBoost model because it has the best accuracy on test data. However, all three models have similar performance and MNB is the fastest, so it could be an acceptable choice if computational resources or time are big considerations. \n",
    "\n",
    "It would be interesting to investigate the posts that the model classifies incorrectly. Since the goal of this tool is to help disentangle messy diagnoses, we could potentially learn a lot from examples that confused the computer. Perhaps the model predicted incorrectly because the human who wrote the post shows signs of having a different condition or more than one condition. That is precisely the kind of application that could be extremely useful to a clinician. \n",
    "\n",
    "I could imagine this tool being available on self-improvement or mental wellness websites, just as you can find screening questionaires for various conditions all over the internet. People who are curious or struggling could submit a sample journal entry and immediately get a few suggestions of illnesses or conditions to learn more about. The mental healthcare system in the US is generally overburdened, so patient self-advocacy is crucial. This tool could allow a patient to bring up their concerns with their doctor and get the right referrals. \n",
    "\n",
    "Clinicians and mental health professionals could also use this tool in conjunction with other long-standing tools in a variety of situations. It could be part of their initial evaluation of a new patient. For a patient who has been in treatment for a while and is still struggling, it could help suggest new areas to explore -- maybe they have only been getting treatment for some of their problems.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
